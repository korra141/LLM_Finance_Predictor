{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quick Fine-tuning Demo for LLM Finance Predictor\n",
        "\n",
        "This notebook demonstrates how to quickly fine-tune a language model for financial prediction tasks.\n",
        "\n",
        "## Overview\n",
        "- Load and prepare financial data\n",
        "- Setup model and training configuration\n",
        "- Fine-tune the model with LoRA\n",
        "- Evaluate model performance\n",
        "- Make predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('../src')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import our custom modules\n",
        "from data.loader import FinancialDataLoader\n",
        "from data.preprocess import FinancialDataPreprocessor\n",
        "from data.dataset import FinancialDataModule\n",
        "from model.finetune import FinancialModelTrainer, FinancialModelEvaluator\n",
        "from model.inference import FinancialPredictionPipeline\n",
        "from utils.logging import FinancialLogger\n",
        "from utils.metrics import FinancialMetrics\n",
        "from utils.prompt_templates import FinancialPromptBuilder\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration Setup\n",
        "\n",
        "Let's create a configuration for our quick demo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create demo configuration\n",
        "demo_config = {\n",
        "    'model': {\n",
        "        'name': 'microsoft/DialoGPT-small',  # Using small model for demo\n",
        "        'size': 'small',\n",
        "        'quantization': None,\n",
        "        'max_length': 256,\n",
        "        'temperature': 0.7,\n",
        "        'top_p': 0.9,\n",
        "        'top_k': 50,\n",
        "        'architecture': {\n",
        "            'use_lora': True,\n",
        "            'lora_rank': 8,  # Smaller rank for demo\n",
        "            'lora_alpha': 16,\n",
        "            'lora_dropout': 0.1,\n",
        "            'target_modules': [\"q_proj\", \"v_proj\"]\n",
        "        }\n",
        "    },\n",
        "    'training': {\n",
        "        'batch_size': 2,  # Small batch for demo\n",
        "        'gradient_accumulation_steps': 2,\n",
        "        'learning_rate': 5e-4,\n",
        "        'num_epochs': 1,  # Single epoch for demo\n",
        "        'warmup_steps': 10,\n",
        "        'weight_decay': 0.01,\n",
        "        'max_grad_norm': 1.0\n",
        "    },\n",
        "    'validation': {\n",
        "        'eval_steps': 50,\n",
        "        'save_steps': 100,\n",
        "        'eval_strategy': 'steps',\n",
        "        'save_strategy': 'steps',\n",
        "        'save_total_limit': 2\n",
        "    },\n",
        "    'logging': {\n",
        "        'log_level': 'info',\n",
        "        'use_wandb': False,  # Disabled for demo\n",
        "        'log_steps': 10\n",
        "    },\n",
        "    'use_retrieval': False,  # Disabled for demo\n",
        "    'target_column': 'price_direction_1d',\n",
        "    'max_length': 256,\n",
        "    'include_context': False\n",
        "}\n",
        "\n",
        "print(\"Demo configuration created:\")\n",
        "print(f\"Model: {demo_config['model']['name']}\")\n",
        "print(f\"LoRA enabled: {demo_config['model']['architecture']['use_lora']}\")\n",
        "print(f\"Training epochs: {demo_config['training']['num_epochs']}\")\n",
        "print(f\"Batch size: {demo_config['training']['batch_size']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare Sample Data\n",
        "\n",
        "Let's create some sample financial data for the demo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample financial data\n",
        "np.random.seed(42)\n",
        "n_samples = 100\n",
        "dates = pd.date_range('2023-01-01', periods=n_samples, freq='D')\n",
        "\n",
        "# Generate sample price data\n",
        "base_price = 100\n",
        "price_changes = np.random.randn(n_samples) * 0.02\n",
        "prices = [base_price]\n",
        "for change in price_changes[1:]:\n",
        "    prices.append(prices[-1] * (1 + change))\n",
        "\n",
        "# Create sample DataFrame\n",
        "sample_data = pd.DataFrame({\n",
        "    'symbol': ['AAPL'] * n_samples,\n",
        "    'date': dates,\n",
        "    'Open': [p * (1 + np.random.randn() * 0.01) for p in prices],\n",
        "    'High': [p * (1 + abs(np.random.randn()) * 0.01) for p in prices],\n",
        "    'Low': [p * (1 - abs(np.random.randn()) * 0.01) for p in prices],\n",
        "    'Close': prices,\n",
        "    'Volume': np.random.randint(1000000, 10000000, n_samples),\n",
        "    'SMA_20': pd.Series(prices).rolling(20).mean(),\n",
        "    'RSI': np.random.uniform(20, 80, n_samples),\n",
        "    'MACD': np.random.randn(n_samples) * 0.5,\n",
        "    'news_count': np.random.randint(0, 5, n_samples),\n",
        "    'sentiment_mean': np.random.uniform(-1, 1, n_samples)\n",
        "})\n",
        "\n",
        "# Create target variable (price direction for next day)\n",
        "sample_data['price_direction_1d'] = (sample_data['Close'].shift(-1) > sample_data['Close']).astype(int)\n",
        "sample_data = sample_data.dropna()\n",
        "\n",
        "print(f\"Sample data created:\")\n",
        "print(f\"Shape: {sample_data.shape}\")\n",
        "print(f\"Date range: {sample_data['date'].min()} to {sample_data['date'].max()}\")\n",
        "print(f\"Target distribution: {sample_data['price_direction_1d'].value_counts().to_dict()}\")\n",
        "\n",
        "# Show sample\n",
        "print(f\"\\nSample data:\")\n",
        "print(sample_data[['date', 'Close', 'SMA_20', 'RSI', 'price_direction_1d']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Setup Data Module\n",
        "\n",
        "Let's prepare the data for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into train/val/test\n",
        "train_size = int(0.7 * len(sample_data))\n",
        "val_size = int(0.15 * len(sample_data))\n",
        "\n",
        "train_data = sample_data[:train_size]\n",
        "val_data = sample_data[train_size:train_size + val_size]\n",
        "test_data = sample_data[train_size + val_size:]\n",
        "\n",
        "print(f\"Data split:\")\n",
        "print(f\"Train: {len(train_data)} samples\")\n",
        "print(f\"Validation: {len(val_data)} samples\")\n",
        "print(f\"Test: {len(test_data)} samples\")\n",
        "\n",
        "# Initialize data module\n",
        "data_module = FinancialDataModule('../configs/base_model.yaml')\n",
        "\n",
        "# Setup tokenizer\n",
        "model_name = demo_config['model']['name']\n",
        "data_module.setup_tokenizer(model_name)\n",
        "\n",
        "# Prepare datasets\n",
        "data_module.prepare_datasets(\n",
        "    train_data, val_data, test_data,\n",
        "    retrieval_index=None  # No retrieval for demo\n",
        ")\n",
        "\n",
        "# Get data loaders\n",
        "train_loader, val_loader, test_loader = data_module.get_data_loaders(\n",
        "    batch_size=demo_config['training']['batch_size'],\n",
        "    num_workers=0,  # No multiprocessing for demo\n",
        "    shuffle_train=True\n",
        ")\n",
        "\n",
        "print(f\"\\nData loaders created:\")\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "# Test a sample batch\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"\\nSample batch:\")\n",
        "print(f\"Input IDs shape: {sample_batch['input_ids'].shape}\")\n",
        "print(f\"Attention mask shape: {sample_batch['attention_mask'].shape}\")\n",
        "print(f\"Labels shape: {sample_batch['labels'].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Initialize Model Trainer\n",
        "\n",
        "Let's setup the model trainer with our configuration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "trainer = FinancialModelTrainer(demo_config)\n",
        "\n",
        "# Get model info\n",
        "model_info = trainer.get_model_info()\n",
        "print(\"Model information:\")\n",
        "for key, value in model_info.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Check if LoRA is properly applied\n",
        "if hasattr(trainer.model, 'print_trainable_parameters'):\n",
        "    print(f\"\\nTrainable parameters:\")\n",
        "    trainer.model.print_trainable_parameters()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train the Model\n",
        "\n",
        "Let's start the training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "output_dir = f\"./models/demo_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Starting training...\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "# Train the model\n",
        "trained_trainer = trainer.train(\n",
        "    train_dataset=train_loader,\n",
        "    eval_dataset=val_loader,\n",
        "    output_dir=output_dir\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluate the Model\n",
        "\n",
        "Let's evaluate the trained model on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize evaluator\n",
        "evaluator = FinancialModelEvaluator(trainer.model, trainer.tokenizer)\n",
        "\n",
        "# Evaluate direction accuracy\n",
        "eval_results = evaluator.evaluate_direction_accuracy(test_loader)\n",
        "\n",
        "print(\"Evaluation results:\")\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "# Calculate additional metrics\n",
        "metrics = FinancialMetrics()\n",
        "\n",
        "# Get predictions for detailed analysis\n",
        "trainer.model.eval()\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(trainer.model.device)\n",
        "        attention_mask = batch['attention_mask'].to(trainer.model.device)\n",
        "        labels = batch['labels'].to(trainer.model.device)\n",
        "        \n",
        "        outputs = trainer.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "        \n",
        "        mask = labels != -100\n",
        "        if mask.any():\n",
        "            all_predictions.extend(predictions[mask].cpu().numpy())\n",
        "            all_labels.extend(labels[mask].cpu().numpy())\n",
        "\n",
        "# Calculate comprehensive metrics\n",
        "comprehensive_metrics = metrics.calculate_direction_accuracy(all_labels, all_predictions)\n",
        "\n",
        "print(f\"\\nComprehensive metrics:\")\n",
        "for key, value in comprehensive_metrics.items():\n",
        "    print(f\"  {key}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Make Predictions\n",
        "\n",
        "Let's test the model with some sample predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize prediction pipeline\n",
        "pipeline = FinancialPredictionPipeline(output_dir, None)\n",
        "\n",
        "# Create sample features for prediction\n",
        "sample_features = {\n",
        "    'symbol': 'AAPL',\n",
        "    'date': '2023-12-01',\n",
        "    'Close': 150.0,\n",
        "    'SMA_20': 148.5,\n",
        "    'RSI': 65.0,\n",
        "    'MACD': 0.5,\n",
        "    'news_count': 3,\n",
        "    'sentiment_mean': 0.2\n",
        "}\n",
        "\n",
        "# Make prediction\n",
        "result = pipeline.run_prediction_pipeline(sample_features, include_explanation=True)\n",
        "\n",
        "print(\"Prediction result:\")\n",
        "print(f\"Direction: {result['prediction']['prediction']['direction']}\")\n",
        "print(f\"Confidence: {result['prediction']['prediction']['confidence']}\")\n",
        "print(f\"Explanation: {result['prediction']['prediction']['explanation']}\")\n",
        "\n",
        "# Test with different features\n",
        "sample_features2 = {\n",
        "    'symbol': 'AAPL',\n",
        "    'date': '2023-12-02',\n",
        "    'Close': 145.0,\n",
        "    'SMA_20': 150.0,\n",
        "    'RSI': 35.0,\n",
        "    'MACD': -0.3,\n",
        "    'news_count': 1,\n",
        "    'sentiment_mean': -0.5\n",
        "}\n",
        "\n",
        "result2 = pipeline.run_prediction_pipeline(sample_features2, include_explanation=True)\n",
        "\n",
        "print(f\"\\nSecond prediction:\")\n",
        "print(f\"Direction: {result2['prediction']['prediction']['direction']}\")\n",
        "print(f\"Confidence: {result2['prediction']['prediction']['confidence']}\")\n",
        "print(f\"Explanation: {result2['prediction']['prediction']['explanation']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Batch Predictions\n",
        "\n",
        "Let's test batch predictions on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features for batch prediction\n",
        "feature_columns = [col for col in test_data.columns if col not in ['symbol', 'date', 'price_direction_1d']]\n",
        "features_list = []\n",
        "\n",
        "for _, row in test_data.iterrows():\n",
        "    features = {col: row[col] for col in feature_columns}\n",
        "    features_list.append(features)\n",
        "\n",
        "print(f\"Prepared {len(features_list)} samples for batch prediction\")\n",
        "\n",
        "# Make batch predictions\n",
        "batch_results = pipeline.run_batch_pipeline(features_list, include_explanations=False)\n",
        "\n",
        "# Analyze results\n",
        "predictions = [result['prediction']['prediction']['direction'] for result in batch_results]\n",
        "true_labels = test_data['price_direction_1d'].values\n",
        "\n",
        "# Calculate accuracy\n",
        "correct = sum(1 for pred, true in zip(predictions, true_labels) \n",
        "              if (pred == 'UP' and true == 1) or (pred == 'DOWN' and true == 0))\n",
        "accuracy = correct / len(predictions)\n",
        "\n",
        "print(f\"\\nBatch prediction results:\")\n",
        "print(f\"Total predictions: {len(predictions)}\")\n",
        "print(f\"Correct predictions: {correct}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Show some examples\n",
        "print(f\"\\nSample predictions:\")\n",
        "for i in range(min(5, len(predictions))):\n",
        "    print(f\"Sample {i+1}: Predicted {predictions[i]}, Actual {true_labels[i]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary and Next Steps\n",
        "\n",
        "Let's summarize what we've accomplished and discuss next steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== QUICK FINE-TUNING DEMO SUMMARY ===\")\n",
        "print(f\"Model: {demo_config['model']['name']}\")\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Validation samples: {len(val_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "print(f\"Training epochs: {demo_config['training']['num_epochs']}\")\n",
        "print(f\"LoRA enabled: {demo_config['model']['architecture']['use_lora']}\")\n",
        "\n",
        "print(f\"\\nPerformance:\")\n",
        "print(f\"Direction accuracy: {eval_results['direction_accuracy']:.4f}\")\n",
        "print(f\"Batch prediction accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nModel saved to: {output_dir}\")\n",
        "\n",
        "print(f\"\\n=== NEXT STEPS ===\")\n",
        "print(\"1. Use more data for better performance\")\n",
        "print(\"2. Experiment with different model architectures\")\n",
        "print(\"3. Add retrieval-augmented generation (RAG)\")\n",
        "print(\"4. Implement more sophisticated prompt engineering\")\n",
        "print(\"5. Add more evaluation metrics\")\n",
        "print(\"6. Deploy the model for real-time predictions\")\n",
        "\n",
        "print(f\"\\n=== DEMO COMPLETED SUCCESSFULLY ===\")\n",
        "print(\"The LLM Finance Predictor has been fine-tuned and is ready for use!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
