{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Fine-tuning Demo for LLM Finance Predictor\n",
    "\n",
    "This notebook demonstrates how to quickly fine-tune a language model for financial prediction tasks.\n",
    "\n",
    "## Overview\n",
    "- Load and prepare financial data\n",
    "- Setup model and training configuration\n",
    "- Fine-tune the model with LoRA\n",
    "- Evaluate model performance\n",
    "- Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "PyTorch version: 2.5.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom modules\n",
    "from data.loader import FinancialDataLoader\n",
    "from data.preprocess import FinancialDataPreprocessor\n",
    "from data.dataset import FinancialDataModule\n",
    "from model.finetune import FinancialModelTrainer, FinancialModelEvaluator\n",
    "from model.inference import FinancialPredictionPipeline\n",
    "from utils.logging import FinancialLogger\n",
    "from utils.metrics import FinancialMetrics\n",
    "from utils.prompt_templates import FinancialPromptBuilder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration Setup\n",
    "\n",
    "Let's create a configuration for our quick demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo configuration created:\n",
      "Model: microsoft/DialoGPT-small\n",
      "LoRA enabled: True\n",
      "Training epochs: 1\n",
      "Batch size: 2\n"
     ]
    }
   ],
   "source": [
    "# Create demo configuration\n",
    "demo_config = {\n",
    "    'model': {\n",
    "        'name': 'microsoft/DialoGPT-small',  # Using small model for demo\n",
    "        'size': 'small',\n",
    "        'quantization': None,\n",
    "        'max_length': 256,\n",
    "        'temperature': 0.7,\n",
    "        'top_p': 0.9,\n",
    "        'top_k': 50,\n",
    "        'architecture': {\n",
    "            'use_lora': True,\n",
    "            'lora_rank': 8,  # Smaller rank for demo\n",
    "            'lora_alpha': 16,\n",
    "            'lora_dropout': 0.1,\n",
    "            'target_modules': [\"c_attn\", \"c_proj\"]\n",
    "        }\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 2,  # Small batch for demo\n",
    "        'gradient_accumulation_steps': 2,\n",
    "        'learning_rate': 5e-4,\n",
    "        'num_epochs': 1,  # Single epoch for demo\n",
    "        'warmup_steps': 10,\n",
    "        'weight_decay': 0.01,\n",
    "        'max_grad_norm': 1.0\n",
    "    },\n",
    "    'validation': {\n",
    "        'eval_steps': 50,\n",
    "        'save_steps': 100,\n",
    "        'eval_strategy': 'steps',\n",
    "        'save_strategy': 'steps',\n",
    "        'save_total_limit': 2\n",
    "    },\n",
    "    'logging': {\n",
    "        'log_level': 'info',\n",
    "        'use_wandb': False,  # Disabled for demo\n",
    "        'log_steps': 10\n",
    "    },\n",
    "    'use_retrieval': False,  # Disabled for demo\n",
    "    'target_column': 'price_direction_1d',\n",
    "    'max_length': 256,\n",
    "    'include_context': False\n",
    "}\n",
    "\n",
    "print(\"Demo configuration created:\")\n",
    "print(f\"Model: {demo_config['model']['name']}\")\n",
    "print(f\"LoRA enabled: {demo_config['model']['architecture']['use_lora']}\")\n",
    "print(f\"Training epochs: {demo_config['training']['num_epochs']}\")\n",
    "print(f\"Batch size: {demo_config['training']['batch_size']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Sample Data\n",
    "\n",
    "Let's create some sample financial data for the demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data created:\n",
      "Shape: (81, 13)\n",
      "Date range: 2023-01-20 00:00:00 to 2023-04-10 00:00:00\n",
      "Target distribution: {'False': 43, 'True': 38}\n",
      "\n",
      "Sample data:\n",
      "         date      Close      SMA_20        RSI price_direction_1d\n",
      "19 2023-01-20  92.122658  102.003501  33.992985               True\n",
      "20 2023-01-21  94.823047  101.744653  40.575612              False\n",
      "21 2023-01-22  94.394871  101.478223  48.438196               True\n",
      "22 2023-01-23  94.522357  101.153578  41.306258              False\n",
      "23 2023-01-24  91.828946  100.540412  58.929370              False\n"
     ]
    }
   ],
   "source": [
    "# Create sample financial data\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "dates = pd.date_range('2023-01-01', periods=n_samples, freq='D')\n",
    "\n",
    "# Generate sample price data\n",
    "base_price = 100\n",
    "price_changes = np.random.randn(n_samples) * 0.02\n",
    "prices = [base_price]\n",
    "for change in price_changes[1:]:\n",
    "    prices.append(prices[-1] * (1 + change))\n",
    "\n",
    "# Create sample DataFrame\n",
    "sample_data = pd.DataFrame({\n",
    "    'symbol': ['AAPL'] * n_samples,\n",
    "    'date': dates,\n",
    "    'Open': [p * (1 + np.random.randn() * 0.01) for p in prices],\n",
    "    'High': [p * (1 + abs(np.random.randn()) * 0.01) for p in prices],\n",
    "    'Low': [p * (1 - abs(np.random.randn()) * 0.01) for p in prices],\n",
    "    'Close': prices,\n",
    "    'Volume': np.random.randint(1000000, 10000000, n_samples),\n",
    "    'SMA_20': pd.Series(prices).rolling(20).mean(),\n",
    "    'RSI': np.random.uniform(20, 80, n_samples),\n",
    "    'MACD': np.random.randn(n_samples) * 0.5,\n",
    "    'news_count': np.random.randint(0, 5, n_samples),\n",
    "    'sentiment_mean': np.random.uniform(-1, 1, n_samples)\n",
    "})\n",
    "\n",
    "# Create target variable (price direction for next day)\n",
    "sample_data['price_direction_1d'] = (sample_data['Close'].shift(-1) > sample_data['Close']).astype(str)\n",
    "sample_data = sample_data.dropna()\n",
    "\n",
    "print(f\"Sample data created:\")\n",
    "print(f\"Shape: {sample_data.shape}\")\n",
    "print(f\"Date range: {sample_data['date'].min()} to {sample_data['date'].max()}\")\n",
    "print(f\"Target distribution: {sample_data['price_direction_1d'].value_counts().to_dict()}\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample data:\")\n",
    "print(sample_data[['date', 'Close', 'SMA_20', 'RSI', 'price_direction_1d']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup Data Module\n",
    "\n",
    "Let's prepare the data for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split:\n",
      "Train: 56 samples\n",
      "Validation: 12 samples\n",
      "Test: 13 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.dataset:Setup tokenizer for model: microsoft/DialoGPT-small\n",
      "INFO:data.dataset:Initialized dataset with 56 samples\n",
      "INFO:data.dataset:Initialized dataset with 12 samples\n",
      "INFO:data.dataset:Initialized dataset with 13 samples\n",
      "INFO:data.dataset:Prepared datasets: 56 train, 12 val, 13 test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data loaders created:\n",
      "Train batches: 28\n",
      "Val batches: 6\n",
      "Test batches: 7\n",
      "\n",
      "Sample batch:\n",
      "Input IDs shape: torch.Size([2, 512])\n",
      "Attention mask shape: torch.Size([2, 512])\n",
      "Labels shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Split data into train/val/test\n",
    "train_size = int(0.7 * len(sample_data))\n",
    "val_size = int(0.15 * len(sample_data))\n",
    "\n",
    "train_data = sample_data[:train_size]\n",
    "val_data = sample_data[train_size:train_size + val_size]\n",
    "test_data = sample_data[train_size + val_size:]\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"Train: {len(train_data)} samples\")\n",
    "print(f\"Validation: {len(val_data)} samples\")\n",
    "print(f\"Test: {len(test_data)} samples\")\n",
    "\n",
    "# Initialize data module\n",
    "data_module = FinancialDataModule('../configs/base_model.yaml')\n",
    "\n",
    "# Setup tokenizer\n",
    "model_name = demo_config['model']['name']\n",
    "data_module.setup_tokenizer(model_name)\n",
    "\n",
    "# Prepare datasets\n",
    "data_module.prepare_datasets(\n",
    "    train_data, val_data, test_data,\n",
    "    retrieval_index=None  # No retrieval for demo\n",
    ")\n",
    "\n",
    "# Get data loaders\n",
    "\n",
    "\n",
    "train_loader, val_loader, test_loader = data_module.get_data_loaders(\n",
    "    batch_size=demo_config['training']['batch_size'],\n",
    "    num_workers=0,  # No multiprocessing for demo\n",
    "    shuffle_train=True\n",
    ")\n",
    "\n",
    "print(f\"\\nData loaders created:\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Test a sample batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch:\")\n",
    "print(f\"Input IDs shape: {sample_batch['input_ids'].shape}\")\n",
    "print(f\"Attention mask shape: {sample_batch['attention_mask'].shape}\")\n",
    "print(f\"Labels shape: {sample_batch['labels'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Model Trainer\n",
    "\n",
    "Let's setup the model trainer with our configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at microsoft/DialoGPT-small and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:model.finetune:Initialized model: microsoft/DialoGPT-small\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 812,544 || all params: 125,253,888 || trainable%: 0.6487\n",
      "Model information:\n",
      "  model_name: microsoft/DialoGPT-small\n",
      "  model_size: small\n",
      "  use_lora: True\n",
      "  trainable_parameters: 812544\n",
      "  total_parameters: 125253888\n",
      "\n",
      "Trainable parameters:\n",
      "trainable params: 812,544 || all params: 125,253,888 || trainable%: 0.6487\n"
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "trainer = FinancialModelTrainer(demo_config)\n",
    "\n",
    "# Get model info\n",
    "model_info = trainer.get_model_info()\n",
    "print(\"Model information:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Check if LoRA is properly applied\n",
    "if hasattr(trainer.model, 'print_trainable_parameters'):\n",
    "    print(f\"\\nTrainable parameters:\")\n",
    "    trainer.model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Model\n",
    "\n",
    "Let's start the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
    "\n",
    "output_dir = f\"./models/demo_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Starting training...\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model.finetune:Model saved to ./models/demo_model_20260204_121240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Train the model\n",
    "# trained_trainer = trainer.train(\n",
    "#     train_dataset=data_module.train_dataset,\n",
    "#     eval_dataset=data_module.val_dataset,\n",
    "#     output_dir=output_dir\n",
    "# )\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model\n",
    "\n",
    "Let's evaluate the trained model on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from ./models/demo_model_20260204_121240 led to unexpected keys not found in the model: score.weight. \n",
      "INFO:model.finetune:Model loaded from ./models/demo_model_20260204_121240\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.load_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot handle batch sizes > 1 if no padding token is defined.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m attention_mask = sample[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m].to(trainer.model.device)\n\u001b[32m      4\u001b[39m labels = sample[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].to(trainer.model.device)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m outputs = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pytorch_updated/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pytorch_updated/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/pytorch_updated/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1387\u001b[39m, in \u001b[36mGPT2ForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1384\u001b[39m     batch_size, sequence_length = inputs_embeds.shape[:\u001b[32m2\u001b[39m]\n\u001b[32m   1386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.pad_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m batch_size != \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1387\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot handle batch sizes > 1 if no padding token is defined.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.pad_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1389\u001b[39m     last_non_pad_token = -\u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Cannot handle batch sizes > 1 if no padding token is defined."
     ]
    }
   ],
   "source": [
    "# sample = next(iter(test_loader))\n",
    "# input_ids = sample['input_ids'].to(trainer.model.device)\n",
    "# attention_mask = sample['attention_mask'].to(trainer.model.device)\n",
    "# labels = sample['labels'].to(trainer.model.device)\n",
    "\n",
    "# outputs = trainer.model(input_ids=input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evalu1ation\n"
     ]
    }
   ],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = FinancialModelEvaluator(trainer.model, trainer.tokenizer)\n",
    "\n",
    "print(\"Starting Evalu1ation\")\n",
    "\n",
    "# Evaluate direction accuracy\n",
    "eval_results = evaluator.evaluate_direction_accuracy(test_loader)\n",
    "\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Calculate additional metrics\n",
    "metrics = FinancialMetrics()\n",
    "\n",
    "# Get predictions for detailed analysis\n",
    "trainer.model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(trainer.model.device)\n",
    "        attention_mask = batch['attention_mask'].to(trainer.model.device)\n",
    "        labels = batch['labels'].to(trainer.model.device)\n",
    "        \n",
    "        outputs = trainer.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        mask = labels != -100\n",
    "        if mask.any():\n",
    "            all_predictions.extend(predictions[mask].cpu().numpy())\n",
    "            all_labels.extend(labels[mask].cpu().numpy())\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "comprehensive_metrics = metrics.calculate_direction_accuracy(all_labels, all_predictions)\n",
    "\n",
    "print(f\"\\nComprehensive metrics:\")\n",
    "for key, value in comprehensive_metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Make Predictions\n",
    "\n",
    "Let's test the model with some sample predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize prediction pipeline\n",
    "pipeline = FinancialPredictionPipeline(output_dir, None)\n",
    "\n",
    "# Create sample features for prediction\n",
    "sample_features = {\n",
    "    'symbol': 'AAPL',\n",
    "    'date': '2023-12-01',\n",
    "    'Close': 150.0,\n",
    "    'SMA_20': 148.5,\n",
    "    'RSI': 65.0,\n",
    "    'MACD': 0.5,\n",
    "    'news_count': 3,\n",
    "    'sentiment_mean': 0.2\n",
    "}\n",
    "\n",
    "# Make prediction\n",
    "result = pipeline.run_prediction_pipeline(sample_features, include_explanation=True)\n",
    "\n",
    "print(\"Prediction result:\")\n",
    "print(f\"Direction: {result['prediction']['prediction']['direction']}\")\n",
    "print(f\"Confidence: {result['prediction']['prediction']['confidence']}\")\n",
    "print(f\"Explanation: {result['prediction']['prediction']['explanation']}\")\n",
    "\n",
    "# Test with different features\n",
    "sample_features2 = {\n",
    "    'symbol': 'AAPL',\n",
    "    'date': '2023-12-02',\n",
    "    'Close': 145.0,\n",
    "    'SMA_20': 150.0,\n",
    "    'RSI': 35.0,\n",
    "    'MACD': -0.3,\n",
    "    'news_count': 1,\n",
    "    'sentiment_mean': -0.5\n",
    "}\n",
    "\n",
    "result2 = pipeline.run_prediction_pipeline(sample_features2, include_explanation=True)\n",
    "\n",
    "print(f\"\\nSecond prediction:\")\n",
    "print(f\"Direction: {result2['prediction']['prediction']['direction']}\")\n",
    "print(f\"Confidence: {result2['prediction']['prediction']['confidence']}\")\n",
    "print(f\"Explanation: {result2['prediction']['prediction']['explanation']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Predictions\n",
    "\n",
    "Let's test batch predictions on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for batch prediction\n",
    "feature_columns = [col for col in test_data.columns if col not in ['symbol', 'date', 'price_direction_1d']]\n",
    "features_list = []\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    features = {col: row[col] for col in feature_columns}\n",
    "    features_list.append(features)\n",
    "\n",
    "print(f\"Prepared {len(features_list)} samples for batch prediction\")\n",
    "\n",
    "# Make batch predictions\n",
    "batch_results = pipeline.run_batch_pipeline(features_list, include_explanations=False)\n",
    "\n",
    "# Analyze results\n",
    "predictions = [result['prediction']['prediction']['direction'] for result in batch_results]\n",
    "true_labels = test_data['price_direction_1d'].values\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = sum(1 for pred, true in zip(predictions, true_labels) \n",
    "              if (pred == 'UP' and true == 1) or (pred == 'DOWN' and true == 0))\n",
    "accuracy = correct / len(predictions)\n",
    "\n",
    "print(f\"\\nBatch prediction results:\")\n",
    "print(f\"Total predictions: {len(predictions)}\")\n",
    "print(f\"Correct predictions: {correct}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Show some examples\n",
    "print(f\"\\nSample predictions:\")\n",
    "for i in range(min(5, len(predictions))):\n",
    "    print(f\"Sample {i+1}: Predicted {predictions[i]}, Actual {true_labels[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "Let's summarize what we've accomplished and discuss next steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== QUICK FINE-TUNING DEMO SUMMARY ===\")\n",
    "print(f\"Model: {demo_config['model']['name']}\")\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"Training epochs: {demo_config['training']['num_epochs']}\")\n",
    "print(f\"LoRA enabled: {demo_config['model']['architecture']['use_lora']}\")\n",
    "\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"Direction accuracy: {eval_results['direction_accuracy']:.4f}\")\n",
    "print(f\"Batch prediction accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nModel saved to: {output_dir}\")\n",
    "\n",
    "print(f\"\\n=== NEXT STEPS ===\")\n",
    "print(\"1. Use more data for better performance\")\n",
    "print(\"2. Experiment with different model architectures\")\n",
    "print(\"3. Add retrieval-augmented generation (RAG)\")\n",
    "print(\"4. Implement more sophisticated prompt engineering\")\n",
    "print(\"5. Add more evaluation metrics\")\n",
    "print(\"6. Deploy the model for real-time predictions\")\n",
    "\n",
    "print(f\"\\n=== DEMO COMPLETED SUCCESSFULLY ===\")\n",
    "print(\"The LLM Finance Predictor has been fine-tuned and is ready for use!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_updated",
   "language": "python",
   "name": "pytorch_updated"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
